{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Template\n",
    "\n",
    "After  niyo daanan yung steps dito, mags-save lahat ng processes na dinaanan niyo sa tested_iterations.csv.\n",
    "\n",
    "Unfortunately, sa dulo niyo pa makikita kung may naulit kayong iteration based sa inputs niyo, so better if sa simula pa lang nagc-check na kayo ng past iterations from the csv.\n",
    "\n",
    "\n",
    "\n",
    "### Don't forget to activate and deactivate your virtual environment! Pwede mag-crash laptop niyo because of this ehe\n",
    "\n",
    "open cmd terminal sa VS Code\n",
    "\n",
    "BEFORE STARTING:\n",
    "`env\\Scripts\\activate.bat`\n",
    "\n",
    "\n",
    "BEFORE CLOSING VS CODE:\n",
    "`env\\Scripts\\deactivate.bat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"./current_iteration_files/x_train.csv\")\n",
    "y_train = pd.read_csv(\"./current_iteration_files/y_train.csv\")\n",
    "x_test = pd.read_csv(\"./current_iteration_files/x_test.csv\")\n",
    "y_test = pd.read_csv(\"./current_iteration_files/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:yellow;\">Run cell below to choose base model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_r2: -1.75\n"
     ]
    }
   ],
   "source": [
    "model_options = [DecisionTreeRegressor(), RandomForestRegressor(), SVR(), LinearRegression()]\n",
    "# neil - linear regression, adrian - random forest, rosette - decision tree, jason - svr\n",
    "\n",
    "model_string = \"\"\n",
    "for i in range(len(model_options)):\n",
    "    model_string = model_string + str(i) + \" : \" + str(model_options[i]) + \" | \"\n",
    "\n",
    "valid_input = False\n",
    "while valid_input == False:\n",
    "\n",
    "    choice = input(\"Choose your base model. \" + model_string + \"Input the integer of your choice. \")\n",
    "\n",
    "    try:\n",
    "        choice = int(choice)\n",
    "        if choice in range(len(model_options)):\n",
    "            valid_input = True\n",
    "    except:\n",
    "        print(\"That is not a valid input. Choose again.\")\n",
    "\n",
    "base_model = model_options[choice]\n",
    "\n",
    "#fit/train model\n",
    "base_model.fit(x_train, y_train)\n",
    "\n",
    "#make predictions \n",
    "predictions = base_model.predict(x_test)\n",
    "\n",
    "#base evaluation\n",
    "base_r2 = round(r2_score(y_test, predictions),2)\n",
    "print(\"base_r2: {:.2f}\".format(base_r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "\n",
    "Edit the grid variable for hyperparameter values you want to test.\n",
    "\n",
    "You can also use RandomSearchCV for hyperparameter tuning\n",
    "\n",
    "<h4 style=\"color:yellow;\">Change grid variable before running cell below</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_r2: -2.6613\n"
     ]
    }
   ],
   "source": [
    "#Keep the grid variable sorted/alphabetized at each level\n",
    "grid = {'criterion':['squared_error', 'poisson'], 'max_depth':[5, 10, 11, 12, 15, 20]}\n",
    "grid = dict(sorted(grid.items()))\n",
    "\n",
    "\n",
    "cvFold = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "gridSearch = GridSearchCV(estimator=base_model, param_grid=grid, n_jobs=-1,\n",
    "\tcv=cvFold, scoring=make_scorer(r2_score))\n",
    "searchResults = gridSearch.fit(x_train, y_train)\n",
    "\n",
    "# extract the best model and evaluate it\n",
    "bestModel = searchResults.best_estimator_\n",
    "best_r2 = bestModel.score(x_test, y_test)\n",
    "print(\"best_r2: {:.4f}\".format(best_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1),\n",
      "             estimator=DecisionTreeRegressor(), n_jobs=-1,\n",
      "             param_grid={'criterion': ['squared_error', 'poisson'],\n",
      "                         'max_depth': [5, 10, 11, 12, 15, 20]},\n",
      "             scoring=make_scorer(r2_score))\n"
     ]
    }
   ],
   "source": [
    "ml_steps = {\"base_model\":str(base_model), \"base_r2\":base_r2, \"hyperparameter tuning\":str(gridSearch),\"best_model\":str(bestModel), \"best_r2\":best_r2}\n",
    "\n",
    "ml = pd.json_normalize(ml_steps)\n",
    "\n",
    "\n",
    "with open(\"./current_iteration_files/preprocessing.json\", \"r\") as outfile: \n",
    "    preprocessing_steps = json.load(outfile, )\n",
    "\n",
    "preprocessing = pd.json_normalize(preprocessing_steps)\n",
    "\n",
    "all_process = pd.concat([preprocessing, ml], axis=1)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "print(all_process[\"hyperparameter tuning\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    iterations = pd.read_csv(\"./tested_iterations.csv\", dtype=str)\n",
    "    new_iterations = pd.concat([iterations,all_process.astype(str)], ignore_index=True, axis=0)\n",
    "    if new_iterations.duplicated().sum() != 0:\n",
    "        print(\"Current steps are duplicate of previous iteration. Current iteration will not be saved in the file.\")\n",
    "    else:\n",
    "        new_iterations.to_csv(\"./tested_iterations.csv\", index=False)\n",
    "\n",
    "except:\n",
    "    all_process.to_csv(\"./tested_iterations.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"color:yellow;\">You can check the tested_iterations.csv for the results of your tests</h4>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
